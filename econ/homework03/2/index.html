<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
                       
  <meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
  <title>Fire!</title>
</head>
 <body>
           
<h1>A Fire Escape Model with Flexible Agent Rules</h1>
     <i> By Laszlo Gulyas, Scott Moser, and Jason Woodard</i><i><br>
     </i><i> July 16, 2003</i><i><br>
     </i>      
<h2>1. Introduction</h2>
      The primary goal of our model was to produce realistic agent behavior 
 using  simple rules that might be generated by an adaptive process. In our 
 experiments,  we focused on the relationship between agents&#8217; range of perception 
 (&#8220;vision&#8221;)  and their collective ability to escape the fire. We found that 
 20/20 vision  can be both a blessing and a curse: a blessing, of course, 
because highly  perceptive agents are more likely to be able to locate an 
escape route; a  curse because crowding and herd behavior may lead agents 
into danger as they  stampede toward an exit on the other side of it. Moreover, 
intermediate levels  of vision can lead to disaster, as explained below.<br>
           
<h2>2. Model</h2>
      We made the following assumptions.<br>
           
<h3>2.1 Topology and Physics </h3>
       There are two primary ingredients to the model: the room in which
the  &#8220;action&#8221; takes place, and the agents that act and react in the room.
We assume  a square room in which agents, doors, fires and obstacles may
be located on a square lattice. This geometry is not endemic to the model;
we could equally have used a hexagonal lattice, for example. The room is
bounded by a wall and contains several doors, fires and obstacles. Each cell
may contain only one object.<br>
  <br>
  The room also contains agents, which may move to a neighboring cell on
the  lattice at a rate of at most one cell per time step. Agents&#8217; decisions
are  simultaneous, which we implemented using a double buffering scheme.
Only one object may occupy a cell at a time. Agents may not move to a space
occupied  by a wall. Moving to a space occupied by fire is fatal.<br>
   
<h3>2.2 Agent Perception and Actions</h3>
  Agent behavior is governed by one of two modes. In &#8220;normal mode,&#8221; agents
 move according to a random walk. In &#8220;emergency&#8221; mode, agents move according
 to the decision rule described in the next section. Agents have limited
vision,  defined by a perception parameter for each agent, which is simply
the maximal  distance at which the agent may observe objects in the room.
As we will see,  the range of vision will play a key role in the behavior
of the agents. <br>
  <br>
  An agent enters &#8220;emergency&#8221; mode when it sees a fire or another agent in
 emergency mode. (We assume an agent&#8217;s state is transparent to the other
agents.)  Once in emergency mode, the agents attempt to avoid the fire and
escape the  room.<br>
         
<h3>2.3 Decision Rules</h3>
  In emergency mode, agents react to the information available them with
the  goal of exiting the room as quickly as possible without touching the
fire.  In each time period, each agent perceives its neighborhood, obtaining
the  following information about the cells in its range of perception:<br>
 
<ul>
   
  <li>Existence and state (mode) of other agents.</li>
 
</ul>
         
<ul>
   
  <li>Existence, direction and distance to the nearest cell occupied by fire, 
doors, and walls.<br>
   </li>
 
</ul>
 
<ul>
   
  <li>&nbsp;Average direction of movement of the neighboring agents.</li>
 
</ul>
 
<ul>
   
  <li>&#8220;Confusion,&#8221; a random noise component.</li>
 
</ul>
 Each component of the information an agent has available can be represented 
as a vector. Given this information, an agent transforms and aggregates the 
information vectors to choose its action. For example, given the direction 
of the fire and the direction of the door (if both are in the agent&#8217;s perceptual 
range), a sensible decision rule might be &#8220;move away from the fire and toward 
the door.&#8221; The generality of these decision rules allows for the exploration 
of emergent decision rules, though the evolution of such rules is not implemented 
here. For the experiments we performed, agents aggregated information in the
following way: agents go toward the door, away from the fire, and in the
general direction of the neighboring agents, all having equal weight. In
addition, there is a stochastic element to the decision rule: a random vector
is incorporated into the agent&#8217;s action with equal weight to the other factors.<br>
 <br>
 In addition to the agent decision rules, there are physical constraints
enforced by the model. For instance, if a move is invalid (if an agent attempts
to walk into wall, for example), the agent moves to a random unoccupied adjacent 
cell if possible; if this is not possible, the agent does not move.<br>
 
<h2>3. Results</h2>
     Our results are mainly qualitative, but informal exploration leads us
 to  believe that they are repeatable and robust to some degree of variation 
 in  the model parameters.<br>
         
<h3>3.1 Perfect vs. Limited Vision</h3>
     Our first experiments focused on the effect of different ranges of vision. 
  In all of these runs, the room consisted of a 50x50 square grid with walls 
  on the boundaries, and a 4 cell-long exit on the top-left corner. The fire 
  occupied a small 2x2 square in the middle of the room and the agents were 
  initially randomly located. The experiments had 100 agents instead of the 
  20 prescribed by the problem description. The reason for this choice was 
 to improve the &#8220;visibility&#8221; of the results, but the phenomena were qualitatively 
  similar in the case of 20 agents, too.<br>
         
<h4>Perfect Information</h4>
     Granting the agents enough vision to see across the room from one corner 
  to the other resulted in most agents escaping the fire, as shown in <a href="movie1.avi">
    Movie 1</a>
    .<br>
     <br>
     The yellow dots represent walls, the green ones stand for the door,
while   the red ones for the fire. Agents are represented with either white
or blue   dots, depending on of their awareness of the fire. The time series 
graph  plots the number of agents who managed to escape and the number of 
deaths  against time.<br>
     <br>
     It seems clear from the movie that the agents&#8217; ability to see the exit 
 from  any location in the room helps them to take an efficient path toward 
 the door. However, once near the door the behavior becomes less determinate. 
 Part of this is due to crowding; part may also result from the loss of precision 
 that occurs when converting the real-valued directional vectors into discrete 
 steps on the lattice.<br>
     <br>
     A look at <a name="chart1_back"></a>
   <a href="#chart1">Chart 1</a>
     also tells us that some agents die, which happens when they step on
a  cell  on fire. That is, some agents march right through the fire, when
their  aim  to the exit and their urge to herd take over their aversion to
fire.<br>
         
<h4>Limited Information: Low Vision</h4>
     The runs reported in <a href="movie2.avi">Movie 2</a>
     and <a name="chart2_back"></a>
   <a href="#chart2">Chart 2</a>
     were carried out with the same parameters as above, except that the
agents&#8217;   vision was set to 10. This means that their moves were based on
information   from a (2*10+1) x (2*10+1) &#8220;window&#8221; around their current location.
Naturally,   agents located in corners of the room had even less information
to use for   their decisions.<br>
     <br>
     This limited amount of information, however, did not prevent the agents
  from escaping successfully. Indeed, <i>all</i> of them managed to safely
 reach the exit, and, as testified by the time series graph, this time without
 casualties. The reason for this is that not being able to see the exits,
their aversion to fire balanced their urge to follow the crowd.<br>
         
<h4>Limited Information: Middle Vision</h4>
     In the last two sections we saw that agents operate well under conditions 
  of both full information and constrained vision. Now, let&#8217;s see what happens 
  if we endow the agents with an intermediate level of vision. The simulations 
  reported in <a href="movie3.avi">Movie 3</a>
     and <a name="chart3_back"></a>
   <a href="#chart3">Chart 3</a>
     were carried out with the same parameters as in the two above runs,
except   for the vision, which was set to 25. That is, an agent located in
the middle   of the room could see all the objects in it, but the farther
away from the   center it moved, the fewer objects that were visible.<br>
     <br>
     The outcome of the simulation is somewhat surprising. The majority of
 the  agents fail to escape the room. Instead, they crowd in the three corners 
 without exits. (More precisely, they crowd in <i>all</i> corners, but the 
 ones happened to be close to the exit leave the room easily.) While the fire
 does not spread in our model, and thus these agents technically survive, 
we consider this behavior as failure, since the behavioral goal of the agents 
 was to find the exit; one could also say that these agents will eventually 
 die of smoke poisoning.<br>
     <br>
     The reason for the failure is that the agents in the corner cannot see 
 the  exits, so the only other applicable rules are to follow the crowd and 
 avoid  the fire. Since the ones a little bit off the corner can actually 
see the  fire, they tend to move towards the corner, yielding an average crowd
direction  that prevents others escaping from it.<br>
         
<h4>Limited Information: Low to Middle Vision</h4>
     The suprising results of the previous section told us that under special 
  conditions, it may actually be more beneficial to know <i>less</i>. To underscore
 this point, we report on another run, where the vision of the agents was
uniformly distributed between 1 and 25. That is, the most knowledgeable agents
had the same level of information as in the previous section, but there were
also agents who knew less.<br>
     <br>
     As the results in <a href="movie4.avi">Movie 4</a>
     and <a name="chart4_back"></a>
   <a href="#chart4">Chart 4</a>
     show, having lower vision actually helps. A majority of the agents escape
  the room, leaving only a few of them behind. It can be seen that the agents
  start to crowd in the corners as before, but then they gradually pull out
  and find alternative routes. The reason for this is that having fewer agents
  that can see the fire from near-corner locations changes the average direction
  of the crowd.<br>
         
<h3>3.2 Coordination and Crowding<br>
     </h3>
     The main lesson from the experiments so far is that the range of vision
  affects the agents&#8217; performance, sometimes in a counterintuitive way. We
 want to emphasize another, more obvious, aspect of these results that we
have not yet discussed, namely that in most cases the agents show coordinated
behavior. In particular, they tend to move in groups. Also, they seem to
move in ways that resemble &#8220;meaningful&#8221; searching behavior. (Recall especially
Movies 2 and 4.) These patterns are not surprising, as we designed the behavioral 
  rules to generate them, but it is still gratifying to see them produced.<br>
     <br>
     Furthermore, in some cases we observe crowding&#8212;another phenomenon to 
be  expected in a highly populated room on fire. Movie 1 shows this effect,
 although  it is partly due to the discretization of directions, as mentioned
 above.  The effect is more pronounced in the part of Movie 2 when the &#8220;last
 group&#8221;  of agents gets to the door. Here agents can be seen clearly to pile
 up at  the door, temporarily unable to get out.<br>
     <br>
     To demonstrate this point even further, we ran another simulation, with
  the parameters of the run shown in Movie 2, except that we limited the
size   of the exit to a single cell in the top-left corner of the room. The
results   of this run can be seen in <a href="movie5.avi">Movie 5</a>
     and <a name="chart5_back"></a>
   <a href="#chart5">Chart 5</a>
    .<br>
     <br>
     It is clear that the smaller size of the door forces the agents to wait
  at the exit. The effect is reienforced by the fact that the size of the
door  does not affect the agents&#8217; ability to approach the exit, but only
prevents  them from taking the final escaping step. We believe that this
can serve as a primitive model of stampedes as well, except that we don&#8217;t
explicitly model death brought on by fellow agents.<br>
     <br>
     Movie 5 displays another piece of novel behavior. What happens is that 
 the  agents that are forced to wait at the exit eventually grow &#8220;inpatient&#8221; 
 and  continue their search. There not being any other way of escape, they 
 finally  get back to where they were before, and crowd again, eventually 
all of them  getting out. Leaving the jammed exit to explore elsewhere seems 
fairly realistic,  and can even be seen as rational. On the other hand, the 
full circle this  &#8220;impatient&#8221; group of agents makes around the circle is a
bit strange. While  one could try to interpret it as &#8220;panicking,&#8221; it may be
more accurately described  as an undesirable artifact of the agents&#8217; decision 
rules.<br>
         
<h3>3.3 Other Experiments</h3>
     We experimented with several other aspects of the model also.<br>
         
<h4> </h4>
 
<h4>Input Weights</h4>
      We tried different weights for the perceptual inputs before settling 
on  a uniform weighting. Extreme values made a difference but did not
seem particularly natural, while a range of intermediate values produced
 qualitatively similar behavior. We still believe it would be interesting
to evolve these rules, but did not see further benefit to hand-tuning them.<br>
   
<h4>Alarm Propagation</h4>
  We included a separate parameter governing the ability of agents to perceive 
  each other&#8217;s state. Under low values of this parameter, news of the fire 
 spreads slowly. A high value simulates the effect of an alarm bell that rings
 when the fire starts and is heard immediately by all agents. Although very
 low values did affect the pattern of agent behavior (especially under higher
 values of the main perception parameter), the effects diminished rapidly
under higher values. We decided not to explore the low-value case more extensively,
 as it seemed unnatural to imagine that agents would be less able to perceive
  other agents&#8217; distress than other aspects of their environment.<br>
   
<h4>Fire Spreading</h4>
We also tried allowing the fire to spread. This did not seem to affect our
basic results, but did allow some agents with middle-range vision to successfully
escape. See <a href="movie6.avi">Movie 6</a>
   and <a name="chart6_back"></a>
  <a href="#chart6">Chart 6</a>
.<br>
         
<h2>4 Future Directions</h2>
     Clearly there is much more one could do; a very partial list follows.<br>
   
<ul>
       
  <li><b>Environmental details</b>. Different topologies, door locations,
 fire spreading patterns; additional obstacles.</li>
   
</ul>
   
<ul>
       
  <li><b>Decision rules</b>.    Evolve or adapt using a genetic algorithm
 or classifier system; allow rules  to be context-dependent (e.g., weight
for fire rule could be higher when closer to fire).</li>
   
</ul>
         
<ul>
       
  <li><b>Agent goals</b>.    Allow agents to pursue multiple goals (e.g.,
 firefighting, rescue) in addition  to escape; explore tension between and
 selection among them.<br>
    </li>
   
</ul>
         
<h4></h4>
   
<h2>Figures</h2>
    <a name="chart1"></a>
    <img src="chart1.gif" alt="Chart 1">
    <br>
  <b>  Chart 1</b> &nbsp;| &nbsp;<a href="#chart1_back">back</a>
   <br>
   <br>
    <a name="chart2"></a>
      <img src="chart2.gif" alt="Chart 2">
    <br>
    <b>Chart 2</b> &nbsp;| &nbsp;<a href="#chart2_back">back</a>
   <br>
   <br>
    <a name="chart3"></a>
      <img src="chart3.gif" alt="Chart 3">
    <br>
    <b>Chart 3</b> &nbsp;| &nbsp;<a href="#chart3_back">back</a>
   <br>
   <br>
    <a name="chart4"></a>
      <img src="chart4.gif" alt="Chart 4">
    <br>
    <b>Chart 4</b> &nbsp;| &nbsp;<a href="#chart4_back">back</a>
   <br>
   <br>
    <a name="chart5"></a>
      <img src="chart5.gif" alt="Chart 5">
    <br>
    <b>Chart 5</b> &nbsp;| &nbsp;<a href="#chart5_back">back</a>
   <br>
        <br>
    <a name="chart6"></a>
      <img src="chart6.gif" alt="Chart 6">
    <br>
    <b>Chart 6</b> &nbsp;| &nbsp;<a href="#chart6_back">back</a>
    <br>
         
<h2>Source Code</h2>
     Our code, written in <a href="http://java.sun.com/">Java</a>
     using the <a href="http://repast.sourceforge.net/">RePast</a>
     agent-based modeling toolkit, is available <a href="fire.tgz">here</a>
  .<br>
           
</body>
</html>
